<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Asgari.Deep Communication</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="../../assets/img/favicon.png" rel="icon">
  <link href="../../assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;600&family=Inconsolata:wght@400;500;600;700&family=Raleway:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="https://unpkg.com/aos@2.3.4/dist/aos.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/npm/swiper@8/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="../../assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: MyPortfolio - v4.9.1
  * Template URL: https://bootstrapmade.com/myportfolio-bootstrap-portfolio-website-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
  <link rel="stylesheet" href="../../shared/nav.css" />

  <!-- Page-specific tweaks -->
  <style>
    /* Inline Swiper carousel that behaves like a standard stacked image block. */
    .dc-carousel{
      width: 100%;
      margin: 18px 0 26px;
      --swiper-navigation-color: #000;
      --swiper-pagination-color: #000;
    }

    .dc-carousel .swiper-slide{ width: 100%; }

    .dc-carousel .swiper-slide img{
      display: block;
      width: 100%;
      height: auto;
    }

    .dc-carousel .swiper-pagination{
      position: relative;
      margin-top: 12px;
    }

    /* Keep navigation arrows inside the image bounds (subtle + consistent). */
    .dc-carousel .swiper-button-prev,
    .dc-carousel .swiper-button-next{
      width: 42px;
      height: 42px;
    }

    .dc-carousel .swiper-button-prev:after,
    .dc-carousel .swiper-button-next:after{
      font-size: 18px;
      font-weight: 700;
    }

    video.dc-video{
      display: block;
      width: 100%;
      height: auto;
    }
  </style>
</head>

<body>

  <div id="sharedNav"></div>

  <main id="main">

    <!-- =====================
         INTRO
    ====================== -->
    <section class="section">
      <div class="container">
        <div class="row mb-4 align-items-center">
          <div class="col-md-10" data-aos="fade-up">
            <h2>Deep Communication</h2>
            <p class="mb-4"><span class="text-muted">Spring 2023 | Professor Allan Sayegh | Created in collaboration with T.D. Radhakrishnan
              </span></p>

            <p>
              Deep Communication investigates storytelling as a multi-channel phenomenon rather than a purely linguistic exchange. The project asks how subjective experience can be represented and transmitted when language is insufficient, and how such representations might be structured to support interpersonal understanding across both intimate and networked contexts. The work operationalizes narrative as signal by capturing physiological and audio inputs and translating them into paired interfaces: a remote system that generates visual accompaniment to spoken narration in real time, and a fabricated wearable that encodes the narrative as embodied form.
            </p>

            <p>
              Across both prototypes, the core methodological commitment is translation without reduction to text alone. Speech, heart rate, and electrophysiological readings were treated as complementary descriptors of a story’s affective and temporal structure, then mapped into visual, haptic, and material outputs designed to be legible to an external viewer or listener.
            </p>
          </div>
        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-md-7" data-aos="fade-up">
              <!-- Intro media only (mouth gif) -->
              <img src="images/intro-assembled-stories.gif" alt="Assembled Stories: remote storytelling visual output" class="img-fluid">
              <img src="images/drawing-1.jpg" alt="Initial drawings exploring story-telling across mediums" class="img-fluid" loading="lazy">
            </div>
            <div class="col-md-4 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <div class="sticky-content">
                <h3 class="h3">Research Question</h3>

                <div class="mb-5">
                  <p>
                    How can a responsive communication system represent and transmit self-experience across body-scale and planetary-scale contexts, translating subjective narrative into shared, multi-sensory outputs that support empathy and perceived interconnectedness?
                  </p>
                </div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- =====================
         REMOTE TRANSLATION (ML)
    ====================== -->
    <section class="section">
      <div class="container">
        <div class="row mb-4 align-items-center">
        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-md-7" data-aos="fade-up">
              <!-- ML charts only -->
              <img src="images/ML.jpg" alt="Machine learning pipeline diagram" class="img-fluid" loading="lazy">
            </div>
            <div class="col-md-4 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <div class="sticky-content">
                <h3 class="h3">Remote Translation</h3>

                <div class="mb-5">
                  <p>
                    The remote prototype implements a pipeline that converts live speech into time-sequenced prompts for image generation. Spoken narration is processed through language detection and transcription, then segmented into short textual units that drive an image model at fixed intervals. This structure preserves the continuity of speech while producing a parallel visual stream, avoiding the interruption typically introduced by manual prompting. In parallel, a heart-rate quotient is mapped to haptic vibration, providing a secondary channel that conveys physiological cadence alongside the narrative.
                  </p>

                  <p>
                    The system was evaluated through small-scale user testing. Participants who did not understand the original spoken language reported extracting affective information from prosody and pacing, supporting the choice to preserve original speech rather than translating content. When visual output and haptic rhythm accompanied the narration, most participants reported increased perceived connectedness and empathy relative to audio-only presentation.
                  </p>
                </div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- =====================
         WEARABLE PROCESS
    ====================== -->
    <section class="section">
      <div class="container">
        <div class="row mb-4 align-items-center">
        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-md-7" data-aos="fade-up">
              <img src="images/drawing-2.jpg" alt="Sketches of wearable forms and potential responsive movement" class="img-fluid" loading="lazy">

              <!-- Study Models Carousel (inline, standard image block) -->
              <div class="swiper dc-carousel" aria-label="Study models carousel">
                <div class="swiper-wrapper">

                  <div class="swiper-slide">
                    <img src="images/studymodel-finsgif.gif" alt="Study model: paper fins connected by thread" class="img-fluid" loading="lazy">
                  </div>

                  <div class="swiper-slide">
                    <img src="images/study-1.jpg" alt="Study model: machine-cut polyurethane equipped with servo motor pulling tension on the hand" class="img-fluid" loading="lazy">
                  </div>

                  <div class="swiper-slide">
                    <img src="images/study-2.jpg" alt="Study model: paper corset" class="img-fluid" loading="lazy">
                  </div>

                  <div class="swiper-slide">
                    <img src="images/study-fin.jpg" alt="Study models: paper fin placement" class="img-fluid" loading="lazy">
                  </div>

                </div>

                <div class="swiper-pagination"></div>
                <div class="swiper-button-prev" aria-label="Previous slide"></div>
                <div class="swiper-button-next" aria-label="Next slide"></div>
              </div>
              <!-- End Study Models Carousel -->

              <img src="images/material-pla.jpg" alt="Photographed material study: structure and deformation of PLA" class="img-fluid" loading="lazy">
              <img src="images/material-tpu.jpg" alt="Photographed material study: structure and deformation of TPU" class="img-fluid" loading="lazy">
              <img src="images/eeg-body.jpg" alt="Mapping electrophysiological readings to the body and translating them as infill" class="img-fluid" loading="lazy">
              <img src="images/dress-animation.gif" alt="3D modeled dress animation" class="img-fluid" loading="lazy">

            </div>
            <div class="col-md-4 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <div class="sticky-content">
                <h3 class="h3">Fashion as Communication: Investigation and Process</h3>

                <div class="mb-5">
                  <p>
                    This branch of the project examines fashion as a communicative system in which identity, affiliation, and narrative are carried through material and silhouette. Drag performance provided a concrete site for this investigation due to its explicit reliance on garment-based storytelling and its history of amplified semiotic expression. The objective was not to treat fashion as ornament, but as an interface capable of encoding and transmitting multi-layered information.
                  </p>

                  <p>
                    I collaborated with Candace Persuasion, the Trans Health Representative at Mass General Hospital and a drag performer, to develop a wearable that extends narrative capacity through computational fabrication. Candace’s performance practice already uses text and styling as declarative messaging; this work asked how physiological and biographical data might be incorporated as additional layers of meaning without reducing lived experience to a single metric.
                  </p>

                  <p>
                    A photogrammetric scan of Candace was captured to support fit and proportional accuracy. To construct an emotional dataset for translation, Candace narrated her transition story under simultaneous physiological monitoring, producing synchronized time-based streams that could be mapped into pattern and material behavior. The intent was to preserve the narrative’s temporal structure and intensity rather than extracting a simplified summary.
                  </p>

                  <p>
                    The electrophysiological readings were treated as a modulation source rather than a diagnostic claim. Changes in signal intensity were used to locate moments of heightened engagement and to drive variation in surface density and panel behavior across the garment.
                  </p>
                </div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- =====================
         FINAL DRESS
    ====================== -->
    <section class="section">
      <div class="container">
        <div class="row mb-4 align-items-center">
        </div>
      </div>

      <div class="site-section pb-0">
        <div class="container">
          <div class="row align-items-stretch">
            <div class="col-md-7" data-aos="fade-up">
              <img src="images/dress-1.jpg" alt="Photo of 3D printed dress on Candace Persuasion (overlayed electrophysiological pattern)" class="img-fluid" loading="lazy">
              <img src="images/dress-3.jpg" alt="Photos of 3D printed dress on Candace Persuasion" class="img-fluid" loading="lazy">
              <img src="images/dress-2.jpg" alt="Photo of 3D printed dress on Candace Persuasion" class="img-fluid" loading="lazy">

            </div>
            <div class="col-md-4 ml-auto" data-aos="fade-up" data-aos-delay="100">
              <div class="sticky-content">
                <h3 class="h3">Final 3D-Printed Wearable</h3>

                <div class="mb-5">
                  <p>
                    The final garment was developed through iterative form studies and material tests, moving from paper and soft-model prototypes into flexible printed assemblies. The fabrication strategy uses individually printed TPU panels that can be assembled and tuned for local movement, producing a surface that behaves as a responsive skin rather than a rigid shell.
                  </p>

                  <p>
                    Physiological time-series data was mapped onto the body to modulate density and pattern across the garment, producing regional variation that corresponds to narrative intensity. The design emphasizes a hyper-feminine silhouette while treating surface articulation as a data-bearing layer. The resulting piece operates as an embodied record of story, structured to be read through movement, texture, and rhythm in performance.
                  </p>
                </div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer class="footer" role="contentinfo">
    <div class="container">
      <!-- Intentionally blank (matches other project pages) -->
    </div>
  </footer>

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="https://unpkg.com/aos@2.3.4/dist/aos.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/isotope-layout@3/dist/isotope.pkgd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/swiper@8/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="../../assets/js/main.js"></script>

  <!-- Inline Swiper init for the study-model carousel -->
  <script>
    (function () {
      const el = document.querySelector('.dc-carousel');
      if (!el || typeof Swiper === 'undefined') return;

      new Swiper(el, {
        speed: 600,
        loop: true,
        slidesPerView: 1,
        pagination: {
          el: el.querySelector('.swiper-pagination'),
          type: 'bullets',
          clickable: true
        },
        navigation: {
          nextEl: el.querySelector('.swiper-button-next'),
          prevEl: el.querySelector('.swiper-button-prev')
        }
      });
    })();
  </script>

  <script src="../../shared/nav.js" defer></script>
</body>

</html>
